EXP.NO: 1

DATE: 
                    
              ACCURACY OF VARIOUS ACTIVATION FUNCTIONS

AIM:
	To test the accuracies of various activation functions.

ALGORITHM:
· Import Libraries: Load TensorFlow, NumPy, and Matplotlib.
· Load MNIST Data: Get training and test data from MNIST.
· Normalize Data: Scale image pixel values to [0, 1].
· Build Model: Create a neural network with Flatten, Dense, Dropout, and Output layers.
· Compile Model: Set optimizer, loss function, and evaluation metric.
· Train Model: Train the model for 8 epochs.
· Evaluate Model: Test the model on unseen data.
· Print Results: Show loss and accuracy values.
· Plot Chart: Create a bar chart to compare model accuracies.
· Show Chart: Display the bar chart.

PROGRAM:
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.datasets import mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0  

activations = ['relu', 'sigmoid', 'tanh', 'softmax', 'swish']
accuracy_results = {}

for activation in activations:

    model = Sequential([
        Flatten(input_shape=(28, 28)),
        Dense(128, activation=activation),
        Dense(10, activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), verbose=0)
    accuracy_results[activation] = history.history['val_accuracy']
plt.figure(figsize=(10, 6))
for activation, accuracy in accuracy_results.items():
    plt.plot(range(1, 6), accuracy, label=activation)

plt.xlabel('Epochs')
plt.ylabel('Validation Accuracy')
plt.title('Accuracy Comparison of Activation Functions')
plt.legend()

plt.show()

OUTPUT:

























RESULT:
	Thus the accuracies of various activation functions have been studied successfully.

EXP.NO: 2

DATE: 
                    
          MLP NEUTRAL NETWORK TO SOLVE THE XOR PROBLEM

AIM:
	To solve the given XOR problem using Multilayer Perceptron Neural Network.


ALGORITHM:
· Import TensorFlow and NumPy.
· Define XOR inputs and outputs.
· Create an MLP with one hidden (ReLU) and one output (Sigmoid) layer.
· Compile with Adam optimizer and binary crossentropy loss.
· Train for 500 epochs.
· Test predictions on XOR inputs.
· Print results.


PROGRAM:
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([[0], [1], [1], [0]])
model = Sequential([
    Dense(4, activation='relu', input_shape=(2,)),  
    Dense(1, activation='sigmoid')  
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X, y, epochs=1000, verbose=0)
predictions = model.predict(X)
print("Predictions:", np.round(predictions).flatten())




OUTPUT:





RESULT:
	Thus, a MLP was built to solve the XOR problem.
EXP.NO: 3

DATE: 
                 
           ARTIFICIAL NEURAL NETWORK TO RECOGNIZE                CHARACTERS AND DIGITS FROM IMAGES


AIM:
	To build a Artificial Neural Network to recognize characters and digits from images.


ALGORITHM:
· Import Libraries: Use Keras and NumPy.
· Load Data: Load MNIST dataset (28x28 images).
· Preprocess Data: Normalize inputs and one-hot encode outputs.
· Build Model: 
1. Add Flatten, Dense (120 neurons, ReLU), and Dense (10 neurons, Softmax) layers.
· Compile: Use Adam optimizer and categorical crossentropy loss.
· Train Model: Train for 10 epochs with validation.
· Evaluate Model: Test accuracy on the test set.
· Predict: Predict classes for test data and display results.


PROGRAM:
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageOps
import os
mnist = keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize and Reshape
x_train, x_test = x_train / 255.0, x_test / 255.0
x_train = x_train.reshape(-1, 28, 28, 1)
x_test = x_test.reshape(-1, 28, 28, 1)

# Define CNN Model (More Layers for Accuracy)
model = keras.Sequential([
    keras.Input(shape=(28, 28, 1)),  
    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2, 2),
    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2, 2),
    keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2, 2),
    keras.layers.Flatten(),
    keras.layers.Dense(256, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# Compile and Train (More epochs for accuracy)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

# Evaluate Model
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"\nTest Accuracy: {test_acc:.4f}")

# Function to Load and Preprocess Image
def load_and_preprocess_image(image_path):
    if not os.path.exists(image_path):
        print("Error: File not found!")
        return None
    
    try:
        img = Image.open(image_path).convert('L')  # Convert to grayscale
        img = ImageOps.invert(img)  # Invert colors (MNIST has white text, black bg)
        img = img.resize((28, 28))  # Resize to match MNIST
        img = np.array(img, dtype=np.float32) / 255.0  # Normalize
        img = img.reshape(1, 28, 28, 1)  # Reshape for model input

        # Debug: Show processed image before prediction
        plt.imshow(img.reshape(28, 28), cmap='gray')
        plt.title("Processed Image")
        plt.axis('off')
        plt.show()

        return img
    except Exception as e:
        print(f"Error loading image: {e}")
        return None

# Provide Image Path
image_path = r"E:\Lab Manuals\DEEP LEARNING\image.png"  # Ensure correct path

# Load and Predict Image
img = load_and_preprocess_image(image_path)

if img is not None:
    predictions = model.predict(img)
    predicted_label = np.argmax(predictions)

    # Show Final Prediction
    plt.imshow(img.reshape(28, 28), cmap='gray')
    plt.title(f"Predicted: {predicted_label}")
    plt.axis('off')
    plt.show()
else:
    print(" Failed to load image.")


OUTPUT:






























RESULT:
	Thus, an Artificial Neural Network to recognize characters and digits from images.
EXP.NO: 4

DATE: 
                 
   PROGRAM USING AUTOENCODERS TO ANALYZE IMAGES FOR IMAGE RECONSTRUCTION TASKS



AIM:
	To write a program using autoencoders to analyze images for image reconstruction tasks


ALGORITHM:
· Import Libraries: Use NumPy, Matplotlib, and Keras modules.
· Load Dataset: Load Fashion MNIST data and normalize it to the range [0, 1].
· Reshape Data: Reshape the data to include the channel dimension (28, 28, 1).
· Build Autoencoder: 
1. Encoder: Use Conv2D and MaxPooling2D layers to compress input.
2. Decoder: Use Conv2D and UpSampling2D layers to reconstruct input.
· Compile Model: Use Adam optimizer and binary crossentropy loss.
· Train Model: Fit the autoencoder on the training data for 5 epochs.
· Test Reconstruction: Generate reconstructed images from test data.
· Visualize Results: Plot original and reconstructed images side by side.

PROGRAM:
from keras.datasets import cifar10
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
(X_train, _), (X_test, _) = cifar10.load_data()
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0
X_train = X_train.reshape((len(X_train), 32, 32, 3))  
X_test = X_test.reshape((len(X_test), 32, 32, 3))
input_img = Input(shape=(32, 32, 3))
x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
encoded = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = UpSampling2D((2, 2))(x)
decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')
autoencoder.fit(X_train, X_train, epochs=10, batch_size=256, shuffle=True, validation_data=(X_test, X_test))
decoded_imgs = autoencoder.predict(X_test)
n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(X_test[i])
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i])
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

plt.show()



OUTPUT:
















RESULT:
	Thus, a program using autoencoders to analyze images for image reconstruction tasks was build successfully.
EXP.NO: 5

DATE: 
                 
  CONVOLUTIONAL NEURAL NETWORK (CNN) FOR SPEECH RECOGNITION



AIM:
	To build Convolutional Neural Network for Speech Recognition task.


ALGORITHM:
· Import Libraries: Use TensorFlow and TensorFlow Datasets.
· Load Dataset: Load the "Speech Commands" dataset and split it into train and test sets.
· Convert to NumPy: Convert the dataset to NumPy format for easier manipulation.
· Build Model: 
1. Add Conv2D layers with ReLU activation.
2. Add MaxPooling2D layers for down-sampling.
3. Flatten the output and add Dense layers for classification.
· Compile Model: Use Adam optimizer and categorical crossentropy loss.
· Train Model: Train the model for 10 epochs on the training data.
· Evaluate Model: Evaluate the model's performance on test data and print accuracy.
· Predict Classes: Use the model to predict classes for test data and display them.


PROGRAM:
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

def generate_dummy_data(num_samples=1000, input_length=16000, num_classes=10):

    X = np.random.rand(num_samples, input_length, 1)  
    y = np.random.randint(0, num_classes, num_samples)  
    y = to_categorical(y, num_classes=num_classes)  
    return X, y
def build_cnn_model(input_shape, num_classes):
    model = tf.keras.Sequential([
        tf.keras.layers.InputLayer(input_shape=input_shape),  
        tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu'),  
        tf.keras.layers.MaxPooling1D(pool_size=2),  
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),
        tf.keras.layers.MaxPooling1D(pool_size=2),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Flatten(),  
        tf.keras.layers.Dense(128, activation='relu'),  
        tf.keras.layers.Dropout(0.5),  
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])
    return model
num_samples = 1000  
input_length = 16000  
num_classes = 10  
X, y = generate_dummy_data(num_samples, input_length, num_classes)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
input_shape = (input_length, 1)  
model = build_cnn_model(input_shape=input_shape, num_classes=num_classes)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
epochs = 10
batch_size = 32
print("Training the model...")
history = model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size)
print("Evaluating the model...")
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")
print("Making predictions on test data...")
predictions = model.predict(X_test)
predicted_classes = np.argmax(predictions, axis=1)
print("First 10 Predictions:")
print(predicted_classes[:10])



OUTPUT:




















RESULT:
	Thus, a Convolutional Neural Network for speech recognition was build successfully.

EX.NO: 6

TRAFFIC  SIGN IMAGE CLASSIFICATION USING CNN
DATE:


AIM:
To develop a CNN-based traffic sign classifier using the GTSRB dataset. The model is trained, evaluated, and saved for future use.
ALGORITHM:
Step 1: Set up the environment by importing necessary libraries (TensorFlow, OpenCV, NumPy, Pandas, etc.).
Step 2: Define the dataset path and initialize empty lists for storing image data and labels.
Step 3: Check if the dataset directory exists; raise an error if it does not.
Step 4: Loop through all class directories (0 to 42):
* Construct the directory path for each class.
* Skip if the directory is missing or contains no images.
* Read, resize, and append each image to the dataset along with its class label.
Step 5: Convert the collected image data and labels into NumPy arrays.
* If no data is found, raise an error.
Step 6: Split the dataset into training and testing sets (80% training, 20% testing).
Step 7: Convert labels into one-hot encoded format for multi-class classification.
Step 8: Define the CNN architecture using multiple convolutional, pooling, dropout, and dense layers.
Step 9: Compile the model using categorical cross-entropy loss and Adam optimizer.
Step 10: Train the model using the training dataset and validate it using the test dataset.
Step 11: Plot training history (accuracy and loss curves).
Step 12: Save the trained model as 'traffic_classifier.h5'.

PROGRAM:
import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout
import matplotlib.pyplot as plt

# Number of classes in the GTSRB dataset
classes = 43

# Path to the dataset
data_dir = r"C:\dlexp\archive\Train"

# Prepare data and labels
data = []
labels = []

# Check if data_dir exists
if not os.path.exists(data_dir):
    raise FileNotFoundError(f"Dataset path does not exist: {data_dir}")

# Load images and labels
for i in range(classes):
    path = os.path.join(data_dir, str(i))
    if not os.path.exists(path):
        print(f"Skipping missing directory: {path}")
        continue

    images = os.listdir(path)
    if len(images) == 0:
        print(f"No images found in {path}")
        continue

    for img in images:
        img_path = os.path.join(path, img)
        try:
            image = cv2.imread(img_path)
            if image is None:
                print(f"Failed to load image: {img_path}")
                continue
            image = cv2.resize(image, (30, 30))
            data.append(image)
            labels.append(i)
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")

# Convert to numpy arrays
data = np.array(data)
labels = np.array(labels)

if data.size == 0:
    raise ValueError("No data was loaded. Please check the dataset path and folder structure.")

print("Data shape:", data.shape)
print("Labels shape:", labels.shape)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)

print("Train set size:", X_train.shape, y_train.shape)
print("Test set size:", X_test.shape, y_test.shape)

# One-hot encode labels
y_train = to_categorical(y_train, classes)
y_test = to_categorical(y_test, classes)

# Model architecture
model = Sequential([
    Conv2D(32, (5, 5), activation='relu', input_shape=(30, 30, 3)),
    Conv2D(64, (5, 5), activation='relu'),
    MaxPool2D((2, 2)),
    Dropout(0.15),

    Conv2D(128, (3, 3), activation='relu'),
    Conv2D(256, (3, 3), activation='relu'),
    MaxPool2D((2, 2)),
    Dropout(0.2),

    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.25),
    Dense(classes, activation='softmax')
])

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
# Train the model
history = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))
# Plot training history
plt.figure(figsize=(20, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid()
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid()
plt.show()
# Save the trained model
model.save('traffic_classifier.h5')
print("Model saved as 'traffic_classifier.h5'")
OUTPUT:
















RESULT:
The trained CNN model successfully classifies traffic signs with high accuracy. The model is saved as 'traffic_classifier.h5' for future use.




EX.NO: 7

HUMAN ACTION RECOGNITION
DATE: 

AIM:
To develop a deep learning model for recognizing human actions from images using EfficientNetB7. This enhances applications in surveillance, sports analysis, and human-computer interaction.
ALGORITHM:
Step 1: Load the dataset, including image file paths and corresponding labels.
Step 2: Visualize class distribution and sample images from the dataset.
Step 3: Preprocess images by resizing and converting them into numpy arrays.
Step 4: Encode labels and apply one-hot encoding for classification.
Step 5: Load the EfficientNetB7 model as a base and freeze its layers.
Step 6: Add custom layers for classification and compile the model.
Step 7: Train the model using the processed image dataset.
Step 8: Evaluate model performance using accuracy and loss plots.
Step 9: Test the model with new images and predict human actions.
Step 10: Display predictions with images for visualization.

PROGRAM:
#Import libraries
import os
import glob
import random
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tqdm import tqdm
from PIL import Image
from tensorflow.keras.utils import to_categorical
import seaborn as sns
import matplotlib.image as img
import matplotlib.pyplot as plt
import plotly.express as px

#Set the correct dataset path
DATASET_PATH = r"C:\Users\rr817\OneDrive\Documents\dl7\archive\Human Action Recognition"

#Load CSV data
train_data = pd.read_csv(os.path.join(DATASET_PATH, "Training_set.csv"))
test_data = pd.read_csv(os.path.join(DATASET_PATH, "Testing_set.csv"))

#Get image file paths
train_fol = glob.glob(os.path.join(DATASET_PATH, "train", "*"))
test_fol = glob.glob(os.path.join(DATASET_PATH, "test", "*"))

#Display first few rows of train data
print("Training Data Preview:")
print(train_data.head())

#Visualize class distribution using Plotly
HAR = train_data['label'].value_counts().reset_index()
HAR.columns = ['label', 'count']

fig = px.pie(HAR, values='count', names='label', title='Distribution of Human Activity')
fig.show()

#Function to display random images from train data
def display_random_images():
    num = random.randint(0, len(train_data) - 1)
    img_filename = train_data.iloc[num]['filename']
    label = train_data.iloc[num]['label']
    img_path = os.path.join(DATASET_PATH, "train", img_filename)
    
    if os.path.exists(img_path):
        image = img.imread(img_path)
        plt.imshow(image)
        plt.title(f"Label: {label}")
        plt.axis('off')
        plt.show()
    else:
        print(f"File not found: {img_path}")

# Display 3 random images
display_random_images()
display_random_images()
display_random_images()

#Prepare image data for training
img_data = []
img_label = []

for i, row in train_data.iterrows():
    img_path = os.path.join(DATASET_PATH, "train", row['filename'])
    if os.path.exists(img_path):
        img = Image.open(img_path)
        img_data.append(np.asarray(img.resize((160, 160))))
        img_label.append(row['label'])

# Convert to numpy arrays
img_data = np.array(img_data)
img_labels = pd.factorize(img_label)[0]
y_train = to_categorical(img_labels)

print(f"Image data shape: {img_data.shape}")
print(f"Label data shape: {y_train.shape}")

#Build the model using EfficientNetB7
img_shape = (160, 160, 3)
efficientnet_model = Sequential()

base_model = tf.keras.applications.EfficientNetB7(
    include_top=False,
    input_shape=img_shape,
    pooling="avg",
    weights="imagenet"
)

# Freeze base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom layers
efficientnet_model.add(base_model)
efficientnet_model.add(Flatten())
efficientnet_model.add(Dense(512, activation="relu"))
efficientnet_model.add(Dense(len(HAR['label']), activation="softmax"))

# Compile the model
efficientnet_model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])
efficientnet_model.summary()

#Train the model
history = efficientnet_model.fit(img_data, y_train, epochs=40, batch_size=32)

#Plot loss and accuracy
plt.figure(figsize=(12, 5))

# Loss plot
plt.subplot(1, 2, 1)
plt.plot(history.history["loss"])
plt.title("Model Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")

# Accuracy plot
plt.subplot(1, 2, 2)
plt.plot(history.history["accuracy"])
plt.title("Model Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")

plt.show()

#Function to predict human action
def read_img(fn):
    img = Image.open(fn)
    return np.asarray(img.resize((160, 160)))

def test_predict(test_image):
    img_array = np.array([read_img(test_image)])
    result = efficientnet_model.predict(img_array)
    predicted_class = np.argmax(result)
    probability = np.max(result) * 100

    label = HAR.iloc[predicted_class]['label']
    print(f"Predicted class: {label} (Probability: {probability:.2f}%)")

    image = img.imread(test_image)
    plt.imshow(image)
    plt.title(f"Prediction: {label}")
    plt.axis('off')
    plt.show()

#Test prediction on random test images
test_img_1 = os.path.join(DATASET_PATH, "test", "Image_1001.jpg")
test_img_2 = os.path.join(DATASET_PATH, "test", "Image_101.jpg")

test_predict(test_img_1)
test_predict(test_img_2)




OUTPUT:






















RESULT:
The model achieved high accuracy in classifying human actions using EfficientNetB7. Predictions were visualized with images, demonstrating reliable recognition of activities.


EX.NO: 8
PREDICTING CREDIT FRAUD WITH TENSORFLOW
DATE:

AIM:
To develop a fraud detection model using TensorFlow that identifies fraudulent transactions with high accuracy.
ALGORITHM:
Step 1: Load the dataset from Google Drive and perform an initial exploration of fraud and normal transactions.
Step 2: Visualize the distribution of transaction time and amount for both fraud and normal cases.
Step 3: Preprocess the data by removing irrelevant features, creating new fraud-indicative features, and normalizing values.
Step 4: Split the dataset into training, validation, and testing sets, ensuring a balanced ratio between fraud and normal transactions.
Step 5: Standardize features to have a mean of 0 and a standard deviation of 1 for efficient model training.
Step 6: Define a neural network with three hidden layers, using the sigmoid activation function and dropout for regularization.
Step 7: Compile and train the model using the Adam optimizer and categorical cross-entropy loss.
Step 8: Evaluate the model performance on validation and test datasets, checking accuracy and loss.
Step 9: Use t-SNE to visualize fraud and normal transactions in a lower-dimensional space.
Step 10: Analyze results and make adjustments if necessary to improve fraud detection accuracy.
PROGRAM:
import pandas as pd 
import numpy as np 
import tensorflow as tf 
from sklearn.model_selection import train_test_split 
import matplotlib.pyplot as plt 
from sklearn.utils import shuffle 
from sklearn.metrics import confusion_matrix 
import seaborn as sns 
import matplotlib.gridspec as gridspec 
from sklearn.preprocessing import StandardScaler 
from sklearn.manifold import TSNE 
from google.colab import drive 
drive.mount('/content/drive') 
df = pd.read_csv("/content/drive/MyDrive/creditcard.csv") 
df.describe() 
print ("Fraud") 
print (df.Time[df.Class == 1].describe()) 
print () 
print ("Normal") 
print (df.Time[df.Class == 0].describe()) 
f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4)) 
bins = 50 
ax1.hist(df.Time[df.Class == 1], bins = bins) 
ax1.set_title('Fraud') 
ax2.hist(df.Time[df.Class == 0], bins = bins) 
ax2.set_title('Normal') 
plt.xlabel('Time (in Seconds)') 
plt.ylabel('Number of Transactions') 
plt.show() 
print ("Fraud") 
print (df.Amount[df.Class == 1].describe()) 
print () 
print ("Normal") 
print (df.Amount[df.Class == 0].describe()) 
f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,4)) 
bins = 30 
ax1.hist(df.Amount[df.Class == 1], bins = bins) 
ax1.set_title('Fraud') 
ax2.hist(df.Amount[df.Class == 0], bins = bins) 
ax2.set_title('Normal') 
plt.xlabel('Amount ($)') 
plt.ylabel('Number of Transactions') 
plt.yscale('log') 
plt.show() 
df['Amount_max_fraud'] = 1 
df.loc[df.Amount <= 2125.87, 'Amount_max_fraud'] = 0 
f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12,6)) 
ax1.scatter(df.Time[df.Class == 1], df.Amount[df.Class == 1]) 
ax1.set_title('Fraud') 
ax2.scatter(df.Time[df.Class == 0], df.Amount[df.Class == 0]) 
ax2.set_title('Normal') 
plt.xlabel('Time (in Seconds)') 
plt.ylabel('Amount') 
plt.show() 
import matplotlib.pyplot as plt 
import seaborn as sns 
import pandas as pd 
import matplotlib.gridspec as gridspec 
# Assuming the target column is 'Class' and 'v_features' is your list of features 
target_column = 'Class'  # Replace with the actual target column name 
v_features = ['Feature1', 'Feature2', 'Feature3']  # Update with the actual feature names 
# Check the columns in the DataFrame 
print("Columns in the DataFrame:", df.columns) 
# Verify that the columns in v_features exist in the DataFrame 
for feature in v_features: 
    if feature not in df.columns: 
        print(f"Warning: {feature} is not found in the DataFrame columns.") 
    else: 
        print(f"{feature} found in DataFrame.") 
# Create the figure and gridspec layout 
plt.figure(figsize=(12, 28*4)) 
gs = gridspec.GridSpec(28, 1) 
# Loop through each feature and plot the distributions for fraudulent and normal transactions 
for i, cn in enumerate(v_features): 
    if cn in df.columns: 
        ax = plt.subplot(gs[i]) 
        sns.histplot(df[cn][df[target_column] == 1], bins=50, color='blue', kde=True, label='Fraud') 
        sns.histplot(df[cn][df[target_column] == 0], bins=50, color='red', kde=True, label='Normal') 
        ax.set_xlabel('') 
        ax.set_title('Histogram of feature: ' + str(cn)) 
        ax.legend() 
    else: 
        print(f"Feature '{cn}' not found in DataFrame.") 
plt.show() 
#Drop all of the features that have very similar distributions between the two types of transactions. 
df = df.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8'], axis =1) 
#Based on the plots above, these features are created to identify values where fraudulent transaction are
df['V1_'] = df.V1.map(lambda x: 1 if x < -3 else 0) 
df['V2_'] = df.V2.map(lambda x: 1 if x > 2.5 else 0) 
df['V3_'] = df.V3.map(lambda x: 1 if x < -4 else 0) 
df['V4_'] = df.V4.map(lambda x: 1 if x > 2.5 else 0) 
df['V5_'] = df.V5.map(lambda x: 1 if x < -4.5 else 0) 
df['V6_'] = df.V6.map(lambda x: 1 if x < -2.5 else 0) 
df['V7_'] = df.V7.map(lambda x: 1 if x < -3 else 0) 
df['V9_'] = df.V9.map(lambda x: 1 if x < -2 else 0) 
df['V10_'] = df.V10.map(lambda x: 1 if x < -2.5 else 0) 
df['V11_'] = df.V11.map(lambda x: 1 if x > 2 else 0) 
df['V12_'] = df.V12.map(lambda x: 1 if x < -2 else 0) 
df['V14_'] = df.V14.map(lambda x: 1 if x < -2.5 else 0) 
df['V16_'] = df.V16.map(lambda x: 1 if x < -2 else 0) 
df['V17_'] = df.V17.map(lambda x: 1 if x < -2 else 0) 
df['V18_'] = df.V18.map(lambda x: 1 if x < -2 else 0) 
df['V19_'] = df.V19.map(lambda x: 1 if x > 1.5 else 0) 
df['V21_'] = df.V21.map(lambda x: 1 if x > 0.6 else 0) 
#Create a new feature for normal (non-fraudulent) transactions. 
df.loc[df.Class == 0, 'Normal'] = 1 
df.loc[df.Class == 1, 'Normal'] = 0 
#Rename 'Class' to 'Fraud'. 
df = df.rename(columns={'Class': 'Fraud'}) 
#492 fraudulent transactions, 284,315 normal transactions. 
#0.172% of transactions were fraud. 
print(df.Normal.value_counts()) 
print() 
print(df.Fraud.value_counts()) 
pd.set_option("display.max_columns",101) 
df.head() 
#Create dataframes of only Fraud and Normal transactions. 
Fraud = df[df.Fraud == 1] 
Normal = df[df.Normal == 1] 
# Set X_train equal to 80% of the fraudulent transactions. 
X_train = Fraud.sample(frac=0.8) 
count_Frauds = len(X_train) 
# Add 80% of the normal transactions to X_train. 
X_train = pd.concat([X_train, Normal.sample(frac = 0.8)], axis = 0) 
# X_test contains all the transaction not in X_train. 
X_test = df.loc[~df.index.isin(X_train.index)] 
#Shuffle the dataframes so that the training is done in a random order. 
X_train = shuffle(X_train) 
X_test = shuffle(X_test) 
#Add our target features to y_train and y_test. 
y_train = X_train.Fraud 
y_train = pd.concat([y_train, X_train.Normal], axis=1) 
y_test = X_test.Fraud 
y_test = pd.concat([y_test, X_test.Normal], axis=1) 
#Drop target features from X_train and X_test. 
X_train = X_train.drop(['Fraud','Normal'], axis = 1) 
X_test = X_test.drop(['Fraud','Normal'], axis = 1) 
#Check to ensure all of the training/testing dataframes are of the correct length 
print(len(X_train)) 
print(len(y_train)) 
print(len(X_test)) 
print(len(y_test)) 
ratio = len(X_train)/count_Frauds 
y_train.Fraud *= ratio 
y_test.Fraud *= ratio 
#Names of all of the features in X_train. 
features = X_train.columns.values 
#Transform each feature in features so that it has a mean of 0 and standard deviation of 1; 
#this helps with training the neural network. 
for feature in features: 
    mean, std = df[feature].mean(), df[feature].std() 
    X_train.loc[:, feature] = (X_train[feature] - mean) / std 
    X_test.loc[:, feature] = (X_test[feature] - mean) / std 
# Split the testing data into validation and testing sets 
split = int(len(y_test)/2) 
inputX = X_train.to_numpy() 
inputY = y_train.to_numpy() 
inputX_valid = X_test.to_numpy()[:split] 
inputY_valid = y_test.to_numpy()[:split] 
inputX_test = X_test.to_numpy()[split:] 
inputY_test = y_test.to_numpy()[split:] 
import tensorflow as tf 
from tensorflow.keras import layers, models 
# Number of input nodes. 
input_nodes = 37 
# Multiplier maintains a fixed ratio of nodes between each layer. 
multiplier = 1.5 
# Number of nodes in each hidden layer 
hidden_nodes1 = 18 
hidden_nodes2 = round(hidden_nodes1 * multiplier) 
hidden_nodes3 = round(hidden_nodes2 * multiplier) 
# Define the model using the Keras Functional API 
inputs = layers.Input(shape=(input_nodes,))  # Input layer 
# layer 1 
x = layers.Dense(hidden_nodes1, activation='sigmoid')(inputs)  # Hidden layer 1 
# layer 2 
x = layers.Dense(hidden_nodes2, activation='sigmoid')(x)  # Hidden layer 2 
# layer 3 
x = layers.Dense(hidden_nodes3, activation='sigmoid')(x)  # Hidden layer 3 
x = layers.Dropout(0.9)(x)  # Dropout layer 
# layer 4 
outputs = layers.Dense(2, activation='softmax')(x)  # Output layer 
# Build the model 
model = models.Model(inputs=inputs, outputs=outputs) 
# Compile the model 
model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.005), 
              loss='categorical_crossentropy', 
              metrics=['accuracy']) 
# Parameters for training 
training_epochs = 5 
batch_size = 2048 
n_samples = y_train.shape[0] 
# Train the model 
history = model.fit(inputX, inputY, epochs=training_epochs, batch_size=batch_size, 
validation_data=(inputX_valid, inputY_valid)) 
# Print the results after training 
print("Optimization Finished!") 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.preprocessing import StandardScaler 
from sklearn.manifold import TSNE 
# Read the data 
tsne_data = pd.read_csv("/content/drive/MyDrive/creditcard.csv") 
# Set df2 equal to all of the fraudulent and 10,000 normal transactions 
df2 = tsne_data[tsne_data.Class == 1] 
df2 = pd.concat([df2, tsne_data[tsne_data.Class == 0].sample(n = 10000)], axis = 0) 
# Scale features to improve the training ability of TSNE 
standard_scaler = StandardScaler() 
df2_std = standard_scaler.fit_transform(df2.drop('Class', axis=1))  # Drop the target column 
# Set y equal to the target values (Class column) 
y = df2.iloc[:,-1].values  # Use .iloc to select the last column 
# Perform t-SNE 
tsne = TSNE(n_components=2, random_state=0) 
x_test_2d = tsne.fit_transform(df2_std) 
# Build the scatter plot with the two types of transactions 
color_map = {0: 'red', 1: 'blue'} 
plt.figure() 
for idx, cl in enumerate(np.unique(y)): 
    plt.scatter(x=x_test_2d[y == cl, 0], 
                y=x_test_2d[y == cl, 1], 
                c=color_map[idx], 
                label=cl) 
plt.xlabel('X in t-SNE') 
plt.ylabel('Y in t-SNE') 
plt.legend(loc='upper left') 
plt.title('t-SNE visualization of test data') 
plt.show() 
#Set df_used to the fraudulent transactions' dataset. 
df_used = Fraud 
#Add 10,000 normal transactions to df_used. 
df_used = pd.concat([df_used, Normal.sample(n = 10000)], axis = 0) 
#Scale features to improve the training ability of TSNE. 
df_used_std = standard_scaler.fit_transform(df_used) 
#Set y_used equal to the target values. 
y_used = df_used.iloc[:,-1].values 
x_test_2d_used = tsne.fit_transform(df_used_std) 
color_map = {1:'red', 0:'blue'} 
plt.figure() 
for idx, cl in enumerate(np.unique(y_used)): 
    plt.scatter(x=x_test_2d_used[y_used==cl,0], 
                y=x_test_2d_used[y_used==cl,1], 
                c=color_map[idx], 
                label=cl) 
plt.xlabel('X in t-SNE') 
plt.ylabel('Y in t-SNE') 
plt.legend(loc='upper left') 
plt.title('t-SNE visualization of test data') 
plt.show()


OUTPUT:




























RESULT:
The trained model achieved high accuracy in detecting fraudulent transactions while minimizing false positives. The t-SNE visualization confirmed clear separation between fraud and normal transactions.


EX.NO: 9
                 IMAGE AUGMENTATION IN DEEP LEARNING
DATE:

AIM:
To enhance the diversity of training data by applying transformations such as flipping, rotation, cropping, and brightness adjustments, improving model generalization and robustness.
ALGORITHM:
Step 1: Load the input image from the dataset.
Step 2: Choose augmentation techniques (e.g., flipping, rotation, brightness adjustment).
Step 3: Apply random flipping (horizontal/vertical) to the image.
Step 4: Apply random rotation within a specified degree range.
Step 5: Adjust brightness and contrast for variation.
Step 6: Resize the image to a fixed size if needed.
Step 7: Add random noise to simulate real-world variations.
Step 8: Apply transformations using an augmentation library (e.g., Albumentations, Imgaug).
Step 9: Store or visualize the augmented images.
Step 10: Use augmented images to train a machine learning model.
PROGRAM:
import random 
from skimage import color 
import pylab as pl  
import os 
import glob 
import numpy as np 
import scipy as sp 
import pandas as pd 
# skimage 
from skimage.io import imshow, imread, imsave 
from skimage.transform import rotate, AffineTransform, warp, rescale, resize, downscale_local_mean 
from skimage import color, data 
from skimage.exposure import adjust_gamma 
from skimage.util import random_noise 
# OpenCV-Python 
import cv2 
# imgaug 
import imageio 
import imgaug as ia 
import imgaug.augmenters as iaa 
# Albumentations 
import albumentations as A 
# Augmentor 
import Augmentor  
# Keras 
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img 
# SOLT 
import solt 
import solt.transforms as slt 
# Visualization 
import matplotlib.pyplot as plt 
import matplotlib.image as mpimg 
import seaborn as sns 
import os
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "1"

import tensorflow as tf  # Import TensorFlow after setting the environment variable

print(1) 
# Set additional display options for report 
pd.set_option("display.max_columns", 100) 
th_props = [('font-size', '13px'), ('background-color', 'white'),  
            ('color', '#666666')] 
td_props = [('font-size', '15px'), ('background-color', 'white')] 
styles = [dict(selector="td", props=td_props), dict(selector="th",  
            props=th_props)] 
print(2) 
# Warnings 
import warnings 
warnings.filterwarnings("ignore") 
# Helper function to display the images in a grid 
def gallery(array, ncols=3): 
    ''' 
    Function to arrange images into a grid. 
    INPUT: 
        array - numpy array containing images 
        ncols - number of columns in resulting image grid 
    OUTPUT: 
        result - reshaped array into a grid with given number of columns 
    ''' 
    nindex, height, width, intensity = array.shape 
    nrows = nindex // ncols 
    assert nindex == nrows * ncols 
    result = (array.reshape(nrows, ncols, height, width, intensity) 
              .swapaxes(1, 2) 
              .reshape(height * nrows, width * ncols, intensity)) 
    return result 
print(3) 
# Data Path (updated to D:/lab) 
Image_Data_Path = r"C:\\Users\\rr817\\OneDrive\Desktop\DL9\\plant-pathology-2020-fgvc7\\images\\"
train_data = pd.read_csv(r"C:\\Users\\rr817\\OneDrive\\Desktop\DL9\\plant-pathology-2020-fgvc7\\train.csv") 
test_data = pd.read_csv(r"C:\\Users\\rr817\\OneDrive\\Desktop\\DL9\\plant-pathology-2020-fgvc7\\test.csv") 
# Loading the training images 
def load_image(image_id): 
    file_path = image_id + ".jpg" 
    image = imread(Image_Data_Path + file_path) 
    return image 
train_images = train_data["image_id"][:50].apply(load_image) 
print(4) 
print(4) 
# Plotting multiple images using subplots 
fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(30, 16)) 
for col in range(3): 
    for row in range(2): 
        ax[row, col].imshow(train_images.loc[train_images.index[row * 3 + col]]) 
        ax[row, col].set_xticks([]) 
        ax[row, col].set_yticks([]) 
image = train_images[15] 
imshow(image) 
print(image.shape) 
print(5) 
# Red filter [R,G,B] 
red_filter = [1, 0, 0] 
# Blue filter 
blue_filter = [0, 0, 1] 
# Green filter 
green_filter = [0, 1, 0] 
# Matplotlib code to display 
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 16)) 
ax[0].imshow(image * red_filter) 
ax[0].set_title("Red Filter", fontweight="bold", size=30) 
ax[1].imshow(image * blue_filter) 
ax[1].set_title("Blue Filter", fontweight="bold", size=30) 
ax[2].imshow(image * green_filter) 
ax[2].set_title("Green Filter", fontweight="bold", size=30) 
print(6) 
# Import color sub-module 
# Converting image to grayscale 
grayscale_image = color.rgb2gray(image) 
grayscale_image.shape 
imshow(grayscale_image) 
# Horizontally flipped 
hflipped_image = np.fliplr(image)  # fliplr reverse the order of columns of pixels in matrix 
# Vertically flipped 
vflipped_image = np.flipud(image)  # flipud reverse the order of rows of pixels in matrix 
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 16)) 
ax[0].imshow(image) 
ax[0].set_title("Original Image", size=30) 
ax[1].imshow(hflipped_image) 
ax[1].set_title("Horizontally flipped", size=30) 
ax[2].imshow(vflipped_image) 
ax[2].set_title("Vertically flipped", size=30) 
# Clockwise rotation 
rot_clockwise_image = rotate(image, angle=45)  
# Anticlockwise rotation 
rot_anticlockwise_image = rotate(image, angle=-45) 
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 16)) 
ax[0].imshow(image) 
ax[0].set_title("Original Image", size=30) 
ax[1].imshow(rot_clockwise_image) 
ax[1].set_title("+45 degree Rotation", size=30) 
ax[2].imshow(rot_anticlockwise_image) 
ax[2].set_title("-45 degree rotation", size=30) 
print(6) 
# Random Crop 
def randRange(a, b): 
    ''' 
    a utility function to generate random float values in desired range 
    ''' 
    return pl.rand() * (b - a) + a 
def randomCrop(im): 
    ''' 
    Cropping the image in the center from a random margin from the borders 
    ''' 
    margin = 1 / 3.5 
    start = [int(randRange(0, im.shape[0] * margin)), 
             int(randRange(0, im.shape[1] * margin))] 
    end = [int(randRange(im.shape[0] * (1-margin), im.shape[0])),  
           int(randRange(im.shape[1] * (1-margin), im.shape[1]))] 
    cropped_image = im[start[0]:end[0], start[1]:end[1]] 
    return cropped_image 
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 12)) 
ax[0].imshow(image) 
ax[0].set_title("Original Image", size=20) 
ax[1].imshow(randomCrop(image)) 
ax[1].set_title("Cropped", size=20) 
# Brightness adjustment 
image_bright = adjust_gamma(image, gamma=0.5, gain=1) 
image_dark = adjust_gamma(image, gamma=2, gain=1) 
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 12)) 
ax[0].imshow(image) 
ax[0].set_title("Original Image", size=20) 
ax[1].imshow(image_bright) 
ax[1].set_title("Brightened Image", size=20) 
ax[2].imshow(image_dark) 
ax[2].set_title("Darkened Image", size=20) 
print(7) 
# Resizing the image 
image_resized = resize(image, (image.shape[0] // 2, image.shape[1] // 2), anti_aliasing=True) 
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(30, 16)) 
ax[0].imshow(image) 
ax[0].set_title("Original Image", size=20) 
ax[1].imshow(image_resized) 
ax[1].set_title("Resized image", size=20) 
# Adding noise to the image 
noisy_image = random_noise(image) 
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(30, 16)) 
ax[0].imshow(image) 
ax[0].set_title("Original Image", size=20) 
ax[1].imshow(noisy_image) 
ax[1].set_title("Image after adding noise", size=20) 
# Example with OpenCV for flips and rotations 
image13 = train_images[13] 
imshow(image13) 
print(image13.shape) 
plt.axis('off') 
# Vertical flip 
img_flip_ud = cv2.flip(image13, 0) 
plt.imshow(img_flip_ud) 
# Horizontal flip 
img_flip_lr = cv2.flip(image13, 1) 
plt.imshow(img_flip_lr) 
fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 12)) 
ax[0].imshow(img_flip_ud) 
ax[0].set_title("Vertical flip", size=20) 
ax[1].imshow(img_flip_lr) 
ax[1].set_title("Horizontal flip", size=20) 
# Rotation using OpenCV 
img_rotate_90_clockwise = cv2.rotate(image13, cv2.ROTATE_90_CLOCKWISE) 
img_rotate_90_counterclockwise = cv2.rotate(image13, cv2.ROTATE_90_COUNTERCLOCKWISE) 
img_rotate_180 = cv2.rotate(image13, cv2.ROTATE_180) 
fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(20, 12)) 
ax[0].imshow(img_rotate_90_clockwise) 
ax[0].set_title("90 degrees clockwise", size=20) 
ax[1].imshow(img_rotate_90_counterclockwise) 
ax[1].set_title("90 degrees anticlockwise", size=20) 
ax[2].imshow(img_rotate_180) 
ax[2].set_title("180 degree rotation", size=20) 
# Resize image using OpenCV 
def resize_image(image, w, h): 
    resized_image = cv2.resize(image, (w, h)) 
    return resized_image 
imshow(resize_image(image13, 500, 500)) 
# Add light to image using OpenCV 
def add_light(image, gamma): 
    invGamma = 1.0 / gamma 
    table = np.array([((i / 255.0) ** invGamma) * 255 
                      for i in np.arange(0, 256)]).astype("uint8") 
    image = cv2.LUT(image, table) 
    return image 
imshow(add_light(image13, 2)) 
# Crop image using OpenCV 
def crop_image(image, y1, y2, x1, x2): 
    image = image[y1:y2, x1:x2] 
    return image 
imshow(crop_image(image13, 200, 800, 250, 1500))  # (y1, y2, x1, x2) 
# Apply Gaussian Blur to the image 
def gaussian_blur(image, blur): 
    image = cv2.GaussianBlur(image, (5, 5), blur) 
    return image 
imshow(gaussian_blur(image13, 0)) 
plt.show()
OUTPUT:

























RESULT:
The augmented images exhibit variations in orientation, brightness, and noise, enhancing dataset diversity. This improves model generalization and robustness in real-world scenarios.



EX.NO: 10
TWITTER SENTIMENT ANALYSIS
DATE:

AIM:
To analyze Twitter data and classify sentiments (positive, negative, neutral, or others) using deep learning techniques.
ALGORITHM:
Step 1: Import necessary libraries such as pandas, numpy, sklearn, and spacy.
Step 2: Load the dataset (twitter_training.csv) into a Pandas DataFrame and display basic details.
Step 3: Preprocess text data by removing stop words and applying lemmatization using spaCy.
Step 4: Encode sentiment labels using LabelEncoder to convert categorical labels into numerical values.
Step 5: Split the dataset into training (80%) and testing (20%) sets using train_test_split().
Step 6: Create a classification pipeline with TfidfVectorizer for feature extraction and MultinomialNB for sentiment classification.
Step 7: Train the model using the processed training data (X_train, y_train).
Step 8: Predict sentiment labels for test data (X_test) and evaluate using accuracy and classification report.
Step 9: Replace MultinomialNB with RandomForestClassifier, retrain the model, and evaluate performance.
Step 10: Test the final model on new text data from twitter_validation.csv and display predicted vs. actual sentiment labels.

PROGRAM:
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import spacy
# Read the dataset with name "Emotion_classify_Data.csv" and store it in a variable df
columns = ['id','country','Label','Text']
df = pd.read_csv("/content/drive/MyDrive/twitter_training.csv", names=columns)
# Print the shape of dataframe
print(df.shape)
# Print top 5 rows
df.head(5)
# Show sample
for i in range(5):
    print(f"{i+1}: {df['Text'][i]} -> {df['Label'][i]}")
df.dropna(inplace=True)
# load english language model and create nlp object from it
nlp = spacy.load("en_core_web_sm")
# use this utility function to get the preprocessed text data
def preprocess(text):
    # remove stop words and lemmatize the text
    doc = nlp(text)
    filtered_tokens = []
    for token in doc:
        if token.is_stop or token.is_punct:
            continue
        filtered_tokens.append(token.lemma_)

    return " ".join(filtered_tokens)
df['Preprocessed Text'] = df['Text'].apply(preprocess)
le_model = LabelEncoder()
df['Label'] = le_model.fit_transform(df['Label'])

X_train, X_test, y_train, y_test = train_test_split(df['Preprocessed Text'], df['Label'],
                                                    test_size=0.2, random_state=42, stratify=df['Label'])
print("Shape of X_train: ", X_train.shape)
print("Shape of X_test: ", X_test.shape)
# Create classifier
clf = Pipeline([
    ('vectorizer_tri_grams', TfidfVectorizer()),
    ('naive_bayes', (MultinomialNB()))
])
# Model training
clf.fit(X_train, y_train)
# Get prediction
y_pred = clf.predict(X_test)
# Print score
print(accuracy_score(y_test, y_pred))
# Print classification report
print(classification_report(y_test, y_pred))
clf = Pipeline([
    ('vectorizer_tri_grams', TfidfVectorizer()),
    ('naive_bayes', (RandomForestClassifier()))
])
clf.fit(X_train, y_train)
# Get the predictions for X_test and store it in y_pred
y_pred = clf.predict(X_test)
# Print Accuracy
print(accuracy_score(y_test, y_pred))
# Print the classfication report
print(classification_report(y_test, y_pred))
test_df = pd.read_csv('/content/drive/MyDrive/twitter_validation.csv', names=columns)
test_df.head()
test_text = test_df['Text'][10]
print(f"{test_text} ===> {test_df['Label'][10]}")
test_text_processed = [preprocess(test_text)]
test_text_processed
test_text = clf.predict(test_text_processed)
classes = ['Irrelevant', 'Natural', 'Negative', 'Positive']
print(f"True Label: {test_df['Label'][10]}")
print(f'Predict Label: {classes[test_text[0]]}')

OUTPUT:




RESULT:
The model achieved a good accuracy in classifying sentiments, with MultinomialNB performing well on textual data. The RandomForestClassifier provided competitive results, but performance varied based on feature extraction.
